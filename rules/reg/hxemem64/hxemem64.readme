README for hxemem64
(1) Goal:
---------
The goal of hxemem64 exerciser is to stress test the nest portion of POWER systems (L3,X-bus,A-bus,Centaur,memory subsystem) in a multitasking environment.

(2) Salient Features:
----------------------------
1.Supports exercising of various page sizes and segments.
2.Supports concurrent test case to stress all memory controllers of the system in parallel.
3.Provides controlling option of memory workload for every supported page pool at each chip level.
4.Provides controlling option of cpu workload at Node->Chip->Core->Threads level.
3.Supports various patterns, read/write/read_compare ratios.
4.Supports specifying a stride for memory access pattern.

(3) Hardware supported & HW test scope:
---------------------------------------
Hxemem64 exerciser is supported on all POWER platforms. 

(4) OS support:
-----------------
AIX: y
Linux: y
BML: y

(5) General info:
-----------------------
hxemem64 test program runs as a user application on top of OS (AIX, BML & Linux).  It supports memory exercising/stress testing at both levels/modes i.e 
"system memory view" and "chip memory view" , which can be controlled through rule file parameter "global_disable_fliters". 
For high performance test  i.e to drive high memory bandwidth and to have control on cpus and memory usage (by using cpu and mem filters facility in rule),
it is necessary to run hxemem64 in "chip memory view mode" by making global rule "global_disable_filter = no" for a given rule file. 
For exercising huge/large pages, prior configuration of pages should be done before running HTX (This is currently done during HTX initial setup time). 
To configure large pages, use following commands:
Linux:
echo <no_of_large_pages>  > /proc/sys/vm/nr_hugepages
AIX:
vmo command can be used to configure large pages on AIX.
16G pages need to be configured through HMC.

In case of Dynamic reconfiguration, if any CPU is removed exerciser will check whether any thread is bound to that CPU, if yes then it will be unbound.
And from next stanza, it will be a free floating cpu workload (runs without binding to any cpu).

(6) Prerequisites:
---------------------
System must be in well balanced configuration with respect to cpus and memory, i.e every available chip must have both cpus and memory in it. 
System should have enough paging/swap space as per the AIX/Linux Performance tuning guidelines for normal operation. 

(7) Description:
-----------------
Objective of hxemem64 is to stress test the memory subsystem by performing various data integrity tests.
Exerciser has capability to test absolute amount or percentage of free memory or number of pages for all supported page sizes(4K, 64K, 2M, 16M and 16G page pools).
Exerciser, during its initial setup stage probes the available free memory for every page pool and
grabs percentage of memory from every page pool by allocating in shared memory segments. Later, based on the operation and filters at every stanza
it decides what amount of memory per page pool is exercised. 

Exerciser supports two types of testing modes:
1)  system memory view.
2)  chip memory view.

System memory view, is enabled based on system/partition configuration. i.e. in following scenarios.
	- when system is booted with shared processor mode.
	- When there is imbalanced cpu and mem configuration, i.e If any of the chips in partition contains only cpus  and no memory  or only mem and no cpus in it.
 
Chip memory view, is enabled in the following scenarios.
	-When system is booted in dedicated processor mode.
	-And when there is good balanced cpu and mem config detected on the partition, i.e  every  available chip  has both cpu and memory configured in it.
	-One can force exercising memory at chip level (even if system having imbalanced config) by setting "global_disable_filters = yes". 


Default mode of action by exerciser based on system config: 
==============================================================================================
Chip no.        has cpu?         has memory? 	    Hxemem64 runs in mode           comments
==============================================================================================
      1       	   Y	      	 N   		     System memory view 	Filters disabled 
      2            N             Y		     System memory view		Filters disabled
      3            Y             Y                   Chip memory view		Filters enabled
      4            N             N                   Ignore			N.A.

There are three types of WRC operations supported
1)MEM
When oper = MEM, entire shared memory segment is written using specified pattern.
Later, read/read_compare operation is performed from beginning of the shared memory segment.

2)DMA
When oper = DMA, shared memory segment is filled through a DMA from disk in chunks
of specified pattern size. The pattern file should exist on the disk. Later, read/read_compare
operation will be performed like MEM.

3)RIM
When oper = RIM, i.e. Write/Read/Flush/Read and then compare.

4)STRIDE
When oper =STRIDE, it will introduce a stride in the memory access pattern. 
The stride size for accessing the memory is defined through a rulefile parameter "stride_sz". 
By default, its value is 128 byte(1 cacheline).
The main intention of this test case is to have more cache misses i.e. L1/L2/L3 misses. 

Patterns:
Pattern is the data which is written to memory by the exerciser for performing the memory ops. 
Rule parameter PATTERN_ID specifies the pattern being used. One can specify pattern in following ways:
	-   Through pattern file
	-   Special patterns like RANDOM and ADDRESS
	-   Through upto 32 byte hexadecimal immediate pattern
Exercise supports upto 9 different patterns for a given stanza.

Memory exerciser performs memory ops and while performing data integrity check if it
encounters a miscompare the exerciser drops to kernel debugger to facilitate debugging
with certain interesting pointers in GPRs, R3 through R9.


(8) Rule file parameters:
-------------------------------
Hxemem64 rule parameters can be classified in 2 sections: Global rules and Stanza specific rules. 
Global rule parameters are generally placed at the top of the rule file i.e before first stanza and
their naming convention is with prefix "global_". These rules are visible/accessible across and beyond all stanzas. 

Description of Global rule parameters:
==============================================================================================
Name : global_alloc_mem_percent
Description: Specifies the percentage of free memory to be allocated for exercising. Value can be specified in the range 1-99.  
This value is applied only on base page pool i.e 4K and/or 64K. 
In case of "chip memory view"  mode, the value is the percentage of free memory from every chip in the system. 
Otherwise, the percentage is applied at system/partition level.

Default: 70
Syntax: Example, 
global_alloc_mem_percent = 70

Notes: Please use this parameter cautiously if you are using above 80% value. "global_alloc_mem_percent" rule 
will be overwritten if "global_alloc_mem_size" global rule parameter is present.
==============================================================================================
Name: global_alloc_mem_size
Description: Specifies the amount of memory in bytes to be allocated for exercising. 
Value can be specified in the range from minimum segment size to max possible size of available free memory. 
In case of "chip memory view" mode, the value is part of free memory from every chip in the system.
Otherwise the mentioned memory size is considered at system level.
Minimum segment size is dependent on rule parameter "global_alloc_segment_size".
Default:  -1
Syntax: Example, 
global_alloc_mem_size  =  1073741824

Notes: Please use this parameter cautiously if you are using above 80%  of total memory.
"global_alloc_mem_size" rule will take priority on "global_alloc_mem_percent".
==============================================================================================
Name: global_alloc_segment_size
Description: Specifies the standard size of each memory segment to be allocated in bytes for base page size pool (4K and/or 64K).
The default segment size which is 256MB will be overwritten with it.
Memory specified in rule "global_alloc_mem_size" or "global_alloc_mem_spercent" is divided in number of segments for exercising.
Specified value must at least be equal to supported base page size(e.g: 64K)
Default:  -1
Syntax: Example, 
global_alloc_segment_size = 536870912

Notes: On Linux platform, the "global_alloc_segment_size" may get modified in exerciser code
if specified value results in overshoot of Linux shm  parameters (shmmax/shmni). 
============================================================================================
Name: global_num_threads
Description: Specifies the num of threads to create to allocate 
memory specified by global_alloc_mem_percent" or "global_alloc_mem_size".
This parameter is valid only in "system memory view" mode.

Note: If "global_num_threads" is specified, then it is advised to specify "global_disable_cpu_bind = yes"
as well for a stanza, so that cpu load is distributed as per OS scheduling policy, 
Otherwise exerciser binds only to first  global_num_threads of available logical cpus. 

Default:
  global_num_threads = -1

Name: global_debug_level
Description: Debug level is at both global and stanza level, global level rule will handle print msgs 
used in modules before first stanza test case commence,it decides on what level of messages to display. For example, if global_debug_level = 3
it displays all messages i.e., important messages, info messages,debug messages and must print messages. 
And if debug level = 1 has mentioned then the debug prints with level 1 and 0 will only be printed (i.e., only MUST and IMP messages).
        Debug_level has 4 values:
        0   (DBG_MUST_PRINT)
        1   (DBG_IMP_PRINT)
        2   (DBG_INFO_PRINT)
        3   (DBG_DEBUG_PRINT)

Notes: This is over written by stanza specific rule "debug_level", Only messages with debug level less than or
equal to the stanza specified debug level are printed.
Higher the debug level more the messages. Don't disturb debug level this is an aid for developer to debug the code issues.
Default: 0
Syntax: Example,
         g_debug_level = 2
==================================================================================================================
Name: global_disable_cpu_bind
Description: This parameter would disable the thread to bind to a particualr cpu for allocating memory. On enabling this parameter, 
threads will be scheduled to run on cpus as per OS scheduling policies and 
thus may not guarantee local memory affinity and performance of exerciser may get affected.

Values Accepted:   YES or NO (YES to disable the binding, NO to enable the binding)
Default: global_disable_cpu_bind  = no
===================================================================================================================
Name: global_startup_delay
Description: This parameter specifies time laps after which the memory exerciser should start allocating memory segments during HTX run.
Since the memory exerciser considers only the free memory on the system for testing, 
it will wait till other HTX exercisers allocate their resources.
The delay can be varied in between 0 to 120 seconds.
Default: 90 seconds.
Syntax: Example,
global_startup_delay = 30
====================================================================================================================
Name: global_disable_filters
Description: This parameter specifies whether to enable cpu and mem filters or not, 
i.e exerciser should view/exercise memory at system level or at chip level. 

Default : global_disable_filters = yes

Notes: global_disable_filter is overwritten to no, if it finds partition is booted in dedicated processor mode and 
Has good balance with cpu and mem configuration as explained in below table.
-----------------------------------------------------------------------------------------------------------
Chip no.       has cpu?     has mem? 		Hxemem64 runs in mode           comments
-----------------------------------------------------------------------------------------------------------
      1       	Y	      N   	  	System memory view	 	Filters disabled 
      2         N             Y			System memory view		Filters disabled
      3         Y             Y                 Chip memory view		Filters enabled ("global_disable_filters" overwritten to "no")
      4         N             N                 Ignore				N.A.
======================================================================================================================

Description of Stanza specific rule parameters.
------------------------------------------------------------

Name: rule_id
Description: Identification string of the rule.
Notes: It can contain only ascii characters, must be specified, and can be 1 to 8 characters long.
Default: No default value
Syntax: For example,
         Rule_id = rule1
----------------------------------------------------------------------------------------------
Name: pattern_id

Description: Specifies the bit pattern to be used for performing memory ops.
Pattern_id could be specified in following ways:
1) Through a pattern file, Pattern data is read from a file with specified length.
2) Through special keywords - RANDOM or ADDRESS
ADDRESS pattern uses 8 byte effective address of a memory location as a pattern.
For RANDOM pattern, exerciser generates 8/4/1 bytes pseudo random data with help of seed. During
compare, same seed is used to regenerate the expected data.
3) Through immediate hexadecimal number, One can specify up to 32 bytes of hexadecimal data to be
used as a pattern.

One can specify upto 9 different patterns using any of the above (1), (2) and (3).

Note: When multiple patterns are specified in the same rule stanza, please refer
SWITCH_PAT_PER_SEG rule parameter for details about how patterns are applied to segments.

Usage:
    Through a pattern file:
    Syntax:
    PATTERN_ID = <name_of_the_pattern_file>(<pattern_size>)
    e.g. PATTERN_ID = HEX55(4096)
    where HEX55 is the pattern file name and pattern size is 4096. Pattern size amount of
    data is read from the file and replicated in the memory region.
    Range: Pattern size must be a power of 2 and is ranging from 8 bytes to 4096 bytes.
    Possible values are 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096.

    RANDOM or ADDRESS are special keywords. To use one of these, one can specify pattern_id
    as follows:
    Eg: PATTERN_ID = RANDOM 
    These special patterns always use 8 byte as a pattern size.
     Immediate hexadecimal pattern can be specified as:
    Eg:
    PATTERN_ID = 0x1010101010101010
    Pattern length must power of 2 and in the range of 8 to 32 bytes.
    Multiple patterns can be specified using any of the above.
    Eg:
    PATTERN_ID = HEX55(4096) RANDOM HEXAA(32) ADDRESS
                 0xA1A2A3A4A5A6A7A8B1B2B3B4B5B6B7B8
---------------------------------------------------------------------------------------------
Name: crash_on_mis

Description: This parameter specifies whether to trap to KDB or not in case of miscompares.
Notes: The value must be "yes" or "no"
Default: "yes"
Syntax: Example,
          crash_on_mis = yes
--------------------------------------------------------------------------------------------
Name: num_oper
 Description: Specifies how many times to repeat the RWR-C operation. One operation is normally 1
 Write , 1 read and 1 Read-Compare. we can specify in one operation how many writes , read onlys
 and read_compares using the corresponding keywords num_writes, num_read_only, num_read_comp.
 For eg 1 operation can be 3 writes, 5 read_onlys and 3 read_compares.
 Notes: The value must be > 0.
 Default: 1
 Syntax: Example,
         num_oper = 1
---------------------------------------------------------------------------------------------
Name: num_writes

 Description:
      Specifies the number of times to write in one operation.
      One operation is normally 1 Write , 1 read and 1 Compare.
      For more details refer num_oper parameter.

 Default: 1

 Syntax: Example,
         num_writes  =  1

----------------------------------------------------------------------------------------------
 Name: num_read_only

 Description: Specifies number of times to perform a read in one operation. One operation is
 normally 1 Write , 1 read and 1 Compare.
Default: 1
 Syntax: Example,
         num_read_only = 1
--------------------------------------------------------------------------------------------
Name: num_read_comp
 Description: Specifies how many times to do a read and compare (after writing) in one operation.
 Note: To use this we shouldn't make num_writes  = 0, it should be atleast 1 which is the
 default value of  num_writes.
 One operation is normally 1 Write ,1 read and 1 Compare.
 Default: 1
 Syntax: Example,
         num_read_comp = 1
---------------------------------------------------------------------------------------------
Name: num_threads

Description:  This parameter is valid only in "system memory view" mode, which specifies the number of threads to spawn.
The value must be >= 1 and <= Number of logical processors, If num_threads is specified more than the number of
logical processors on the partition it is rounded off to number of logical processors.

Note: If "num_threads" is specified, then it is advised to specify "disable_cpu_bind = yes" as well 
for that stanza so that cpu load is distributed as per OS scheduling policy, 
Otherwise exerciser binds only to first num_threads of available logical cpus. 
Default:
  num_threads = -1
-----------------------------------------------------------------------------------------
Name: disable_cpu_bind
Description: This parameter would enable the thread to bind to a particualr cpu for carrying out various operation.
On enabling this parameter, the threads will be scheduled to run on cpus as per OS scheduling policies.  
  Values Accepted:    YES or NO (YES to avoid binding, NO for enable binding)
  Default: disable_cpu_bind = no
-----------------------------------------------------------------------------------------
Name: oper
Description: Specifies the mode of operation for the threads to execute. The various operations supported are DMA, MEM, RIM, STRIDE etc.
Please see (7)DESCRIPTION section of  this document  for detailed explanation on individual operation.
Notes: The value must be DMA or MEM or RIM or STRIDE.
 Default: MEM
 Syntax: Example,
        oper = mem
-----------------------------------------------------------------------------------------
Name: Name: seg_size_4k, seg_size_64k, seg_size_2m, seg_size_16m, seg_size_16g
Description: Specify the size of the memory segment region in bytes which will be filled using
the given page size. For eg: SEG_SIZE_64K = 2097152 , this will ask to exercise 2MB  memory from created shared memory segment (256MB by default)
of 64K page size.

Notes:  1. The value must be >= page_size  or  <= 268435456 ( or less than if global_alloc_mem_size  is mentioned) .
      	2. Please ensure that the segment size should be multiple of the page size.
Default:
      For 4K,64K page sizes, the default segment size  is  equal to 256MB
      For huge/large pages, the page size itself is the default segment size(for eg: segment size = 2MB for 2MB page size)

 Syntax: Example,
         Seg_size_4k = 8192
-----------------------------------------------------------------------------------------
Name: width
Description: Specify whether 1 byte, 4 byte or 8 byte load/store instructions will be used to fill
the shared memory buffers on memory operations.
Notes: The value must be 1, 4, or 8.
This parameter is ignored for DMA write operations. Because  when written into the segment using
the file operation (read) system call test case specifies the size of the pattern mentioned in rule.

Default: 8
 Syntax: Example,
         width = 8
-----------------------------------------------------------------------------------------
Name: debug_level
 Description: Debug level decides on what level of messages to display. 
        Debug_level has 4 values:
        0   (DBG_MUST_PRINT)
        1   (DBG_IMP_PRINT)
        2   (DBG_INFO_PRINT)
        3   (DBG_DEBUG_PRINT)

 Notes:    Only messages with debug level less than or equal to the stanza specified debug level
 are printed. Higher the debug level more the messages.
 Default: 0
 Syntax: Example,
         debug_level = 2

 Note: Do not disturb debug level, as this is an aid for developer to debug the code issues.
----------------------------------------------------------------------------------------------
Name: mem_percent

Description: This parameter is valid only in "system memory view" mode, Specifies the 
percentage of memory to be used for exercising from allocated memory using
global_alloc_mem_percent or global_alloc_mem_size. We can specify a range from 1-100.
Default: 100
 Syntax: Example,
         mem_percent = 80
----------------------------------------------------------------------------------------------
Name: cpu_percent
Description: This parameter is valid only in "system memory view mode", 
Specifies the percent of logical cpus present in system(or % of  global_num_threads value). 

Note: If "cpu_percent" is specified, then it is advised to specify "disable_cpu_bind = yes" as well 
for same stanza, so that cpu load is distributed as per OS scheduling policy, 
Otherwise exerciser binds only to first  % of available logical cpus. 
----------------------------------------------------------------------------------------------
Name: switch_pat_per_seg
This parameter specifies whether to use all the patterns on each memory segment or to use
specified pattern on each memory segment.
This is valid for OPER = MEM and OPER = RIM or OPER = STRIDE

There are three possible values for this parameter as below.
SWITCH_PAT_PER_SEG = ALL
If ALL is selected all the patterns are tested on each memory segment.

SWITCH_PAT_PER_SEG = YES
 If yes is selected, it makes sure to use a particular pattern for each memory segment. Here
 pattern will be switched for each segment.

SWITCH_PAT_PER_SEG = NO
Fixed pattern would be used for all segments.
Refer pattern_id section for more details.
----------------------------------------------------------------------------------------------
Name: stride_sz
Description: This parameter specifies the stride size. This is valid only for stride testcase.

Default: 128

Syntax: Example
stride_sz=128
----------------------------------------------------------------------------------------------
NAME: affinity
Description: This parameter is valid only in "chip memory view" mode(global_disable_fiters=no),
specifies relationship between cpu and memory based on cpu_filter and mem_filter. Supported values are 
LOCAL,REMOTE_CHIP,REMOTE_NODE, FLOATING, RANDOM.

LOCAL: Memory from  a chip is exercised by binding to cpus from same chip. 
REMOTE_CHIP: Memory from a chip is exercised by binding to cpus from next chip's cpus in a round robin fashion.
REMOTE_NODE: Memory from a chip is exercised by binding to cpus from  chip belongs to next node.
FLOATING: Memory from a chip is exercised without binding to any specific cpus. 
RANDOM: Memory from a chip is exercised by binding to random selected cpus  from whole system.

NOTE:  REMOTE_NODE and RANDOM are not supported currently. 
Default: LOCAL
Syntax: Example
affinity = LOCAL
----------------------------------------------------------------------------------------------
NAME:cpu_filter
Description: This parameter is valid only in "chip memory view mode"(global_disable_fiters=no),
Specifies usage of cpus in system hierarchy manner i.e  node->chip->core->cpu. And decides number of threads to be created for
an operation.

Format: N<tok>P<tok>C<tok>T<tok>
<tok> can be one of    *, single absolute numbers, range (format: [num1-num2]), multiple absolute numbers (format:[num1,num2,num5]), mix of
range and absolute numbers (format:[num1-num3,num6]), percentage (format: %num or [%num]).
Multiple filters (upto to 8) can be specified with space as a separation delimiter.  
A single effective filter mask will be derived by exerciser from all specified cpu filters.

Default: cpu_filter =  N*P*C*T*

Valid cpu filter Examples with description :
1.	N*P*C*T*	 : Enable use of all available cpus in the system.
2.	N*P*C*T0 	 : Enable use of only thread 0 from every core in the system.
3.	N0P0C0T0	 : Single thread operation, uses  cpu 0  to bind and run, cpu 0 is 0th cpu of Node0, chip0,core0.
4.	N*P*C[0,5-7]T*  or N*P*C0T*  N*P*C[5-7]T*	or	N*P*C[0,5,6,7]T*       
			   Use all cpus  only  from cores 0,5,6,7 of all chips in the system to bind and run.
5.	N*P%50C*T*	 : Use  cpus of  first 50%  chips from every node. 

Below are some examples of invalid format of cpu_filter, Exerciser behavior is unexpected in such cases.  
1.	NPCT*		 :  entry at every node.chip,core,thread level must have a valid <tok> as explained above. 
2.	N*P*C%50 	 :  specified filter must have all four entries N,P,C and T.
3.	N*P*C*T50%       :  correct usage is  N*P*C*T%50
4.	N*P*C*T0-3 	 :  When range is specified, it must be in "[ ]",correct usage is N*P*C*T[0-3].
5.	N*P*C0,3T*	 :  correct usage is N*P*C[0,3]T* or  "N*P*C0T*  N*P*C3T*" or "N*P*C[0]*T* N*P*C[3]*T*"
6.	N*P*C*T[]        :  [ ] cannot be empty.

Note: 	1. Numbers that represent NPCT are always logically contiguous. 
	2. When absolute numbers are specified in cpu_filter, User must make sure that numbers are within 
	   boundaries of node, chip, core and, thread on that system.
----------------------------------------------------------------------------------------------
Name : mem_filter
Description: This parameter is valid only in chip memory view mode(global_disable_fiters=no),
Specifies usage of memory per page_size pool, in system hierarchy manner node->chip.

Format: N<tok1>P<tok1>[<page_size1>_<tok2>, <page_size2>_<tok2>]
tok1 	   :It can be any of  *, single absolute numbers. 
page_size  :4K,64K,2M and/or 16M  (both case 'k' or 'K','m' or 'M'  supported in mem_filter).  
	    Page sizes, which do not support for a given system are ignored by exerciser and 
	    continues exercising mem by considering only supported and filter mentioned page size pools. 

tok2	   :can be any of  %, absolute value with suffix MB or GB, number of pages with suffix #. For base page size (i.e 4k and/or 64K) 
       	    this filter value is applied on allocated memory for that chip as per global rules global_alloc_mem_percent or global_alloc_mem_size.
       	    And for huge page size (i.e 2M or 16M) the filter value is applied on free memory backed with huge page size.

Multiple filters (upto to 8) can be specified with space as a separation delimiter.  
A single effective filter mask will be derived by exerciser from all specified mem filters.

Default: mem_filter = N*P*[4K_100%,64K_100%,2M_100%,16M_100%]

Valid mem_filter examples 
1.N*P*[4K_50%,64K_50%,2M_#20,16M_#20]		        :  50% memory from 4K and/or 64K page pool  and 20 huge pages from 2M or 16M page pool  is exercised. 
2.N0P0[2M_100%,16M_100%]  N0P1[2M_100%,16M_100%]   :  All supported  huge pages(2M or 16M) are exercised from first 2 chips of node 0. 
3.N0P0[4K_512MB,64K_512MB]  N1P1[4K_1GB,64K_1GB]  


Invalid or not supported mem_filter format examples, Exerciser behavior is unexpected in such cases.  
1.N*P*[4K_50%,4K_1GB]	: same page size for a chip cannot be repeated in a filter or by using multiple filters. 
2.N*p*[64K_1024KB]	: KB  or TB or Bytes is not supported.
3.N0P[0-2][16M_100%]	: range or % supported at chip level is not supported, usage of multiple filters is the alternative. 
4.NP*[4K_100%,64K_100%] : N<tok> is missing.


Note: 	1. Numbers that represent NP are always logically contiguous. 
	2. When absolute numbers are specified with NP in mem_filter , 
	   User must make sure that numbers are within  boundaries of node, chip on that system.
	3. When absolute sizes are specified with page_sizes (i.e MB, GB or #), User must make sure that the size should be less than the available free memory and
	   also, less than the allocated memory using global_alloc_mem_percent.

==================================================================================================================

(9) filters and affinity relation.
-------------------------------------------
User must specify filters accordingly, such that it should full fill the affinity requirement.  For default values of cpu_filter and mem_filter,
exerciser internally takes care of affinity by overwriting current affinity or by ignoring imbalanced chip.

Some invalid combination examples:
      1.affinity = local
	cpu_filter = N0P0C*T*
	mem_filter = N0P1[64K_100%,16M_100%]

      2.affinity = remote_chip
	cpu_filter = N0P0C*T*	  
	mem_filter = N0P0[64K_100%,16M_100%]

(10) Miscompare Analysis,
--------------------------------------------------------
For AIX miscompare registers are interpreted as:
 gpr3 = 0xFFFFFFFFBEAFDEAD.
 gpr4 = Miscompare offset in number of dwords/words/bytes offset from starting address of
 the segment.
 gpr5 = Starting Address of the Segment Buffer.
 gpr6 = Address of the Pattern buffer. 
 gpr7 = Address of the miscomparing location in the segment buffer.
 gpr8 = Structure which has dwords consecutively of
    a) oper  b)seg_number,   
    c) page_size_index(0=4k,1=64k,2=2M,3=16M,4=16G page size),
    d) width(8/4/1)     e) the segment size     f) owning_thread
    g) cpu_owning_chip    h) mem_owning_chip   
    i) affinity_index (1=LOCAL,2=REMOTE_CHIP,3=FLOATING,4=INTRA_NODE,5=INTER_NODE,6=ABOSOLUTE)
    j) Address of owning thread structure. 	
    k) Address of  global structure "g_data".
    l) sub segment number in case of 16G and RIM test case.
    m)  sub segment size in case of 16G and RIM test case.
    n) Total load/store access for this segment. 
gpr9 = Current rule stanza pointer. 
----------------------------------------------------------------------------------------

(11) Exerciser specific log file:
-------------------------------------
echo $HTX_LOG_DIR
/tmp/

hxemem64 creates log file "$HTX_LOG_DIR/htx/hxemem64/mem/mem_segment_details" on test machine.

#cat mem_segment_details | head

******************************************************************************************************************************************************
 In_use_seg_num  page_size      Owning_thread   cpu_num         mem_chip_num     segment_id              segment_size            segment_EA
================================================================================================================================================
        0        64K             0               1               0               1065686736              239140864               0x3fff55bf0000
        1        64K             0               1               0               1065785043              239140864               0x3fff393d0000
        2        64K             0               1               0               1065752274              239140864               0x3fff2afc0000
        3        64K             0               1               0               1065719505              239140864               0x3fff477e0000
        4        64K             1               9               0               1065817812              239140864               0x3fff6dbf0000

 (12) Understanding htxstats:
----------------------------------
Stats for hxemem64 mainly tells about the Bandwidth at the system/partition level 
i.e number of bytes written/read per second to/from memory.

hxemem64 stats appear as follows:

mem:
  cycles                              =                  1
  # good reads                        =                  0
  # bytes read                        =   3394396137521152
  # good writes                       =                  0
  # total instructions                =                  0
  # bytes written                     =   1697242173014016
  # good others                       =                  0
  # bad others                        =                  0
  # bad reads                         =                  0
  # bad writes                        =                  0
  # data transfer rate(bytes_wrtn/s)  =        10682474496.00
  # data transfer rate(bytes_read/s)  =        21364391936.00
  # instruction throughput(MIPS)      =           0.000000


(13) Limitations:
---------------------
When a memory test fails i.e. when the exerciser determines that the result of a test rule 
is not as expected, it is up to the hardware engineers to determine the exact cause and 
location of error with FSP or some other means. In other words, while the exerciser will be 
helpful is stress testing the memory subsystem in a multitasking environment, it will not be
able to provide low level details/diagnostics about the failure. It can only tell which tests 
have failed and some high level cpu information.

Software Notes:
We obtain and exercise shared memory instead of the memory from the heap. This is due to the 
fact that in case of shared memory at least up to 2 GB of memory can be obtained where as in the
latter case, malloc() gets memory from the private data area of the process which will be much lesser.
